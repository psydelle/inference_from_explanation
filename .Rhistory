### Structure judgments
fit_structure_judgment %>%
gather_draws(b_Intercept,
b_explanation1,
b_norm1,
`b_explanation1:norm1`) %>%
mean_hdi() %>%
rename(term = .variable,
estimate = .value,
`lower 95% CI` = .lower,
`upper 95% CI` = .upper) %>%
select(-c(.width, .point, .interval)) %>%
mutate(term = tolower(term),
term = str_remove_all(term, "b_"),
term = str_remove_all(term, "1"),
term = factor(term, levels = c("intercept", "explanation", "norm", "explanation:norm"))) %>%
arrange(term) %>%
print_table()
### Selection patterns
df.structure %>%
select(participant, judgment, norm, structure, selection) %>%
pivot_wider(names_from = "structure",
values_from = "selection") %>%
count(disjunctive, conjunctive) %>%
print_table()
### Difference scores in structure inference based on causal selections
df.structure %>%
select(participant, explanation, judgment, norm, structure, selection) %>%
pivot_wider(names_from = "structure",
values_from = "selection") %>%
mutate(disjunctive = str_c("D: ", disjunctive),
conjunctive = str_c("C: ", conjunctive)) %>%
unite("selection", c(disjunctive, conjunctive), sep = " & ", remove = F) %>%
group_by(explanation, selection) %>%
summarize(judgment = mean(judgment),
n = n()) %>%
pivot_wider(names_from = explanation,
values_from = c(judgment, n)) %>%
ungroup() %>%
mutate(difference = judgment_abnormal - judgment_normal,
n = n_abnormal + n_normal) %>%
select(-c(n_abnormal, n_normal)) %>%
mutate(across(where(is.numeric), ~ round(., 2))) %>%
print_table()
# Comparisons
# experiment 1: percentage of choosing the abnormal cause as a function of causal structure
df.normality %>%
group_by(structure) %>%
summarize(percentage = sum(selection == "abnormal")/n()) %>%
mutate(across(where(is.numeric), ~ round(., 2) * 100))
# experiment 1: normality inference as a function of causal structure
df.normality %>%
group_by(structure) %>%
summarize(judgment_mean = mean(judgment),
judgment_sd = sd(judgment)) %>%
mutate(across(where(is.numeric), ~ round(., 2)))
# experiment 2: percentage of choosing the abnormal cause as a function of causal structure
df.structure %>%
group_by(structure) %>%
summarize(percentage = sum(selection == "abnormal")/n()) %>%
mutate(across(where(is.numeric), ~ round(., 2) * 100))
# experiment 2: structure inference as a function of normality
df.structure %>%
group_by(explanation) %>%
summarize(judgment_mean = mean(judgment),
judgment_sd = sd(judgment)) %>%
mutate(across(where(is.numeric), ~ round(., 2)))
# Appendix
## Frequentist analysis
### Experiment 1
#### Causal selections
# model fit
# inconsistency between bayesian and freq analysis. by participant random slope missing here.
# power analysis done post stats
ffit_normality_selection = glm(formula = selection ~ structure * norm,
family = "binomial",
data = df.normality)
# analysis of deviance & effect size
aov_normality_selection = Anova(ffit_normality_selection,
type = 3) %>%
as_tibble(rownames = "Term") %>%
mutate(cramers_v = map(`LR Chisq`, ~ chisq_to_cramers_v(chisq = .,
n = nrow(df.normality),
nrow = 2,
ncol = 2))) %>%
unnest(cramers_v)
aov_normality_selection %>%
print_table()
##### Power analysis
table_normality_selection = table(df.normality$structure,
df.normality$selection)
pwr.chisq.test(w = table_normality_selection %>%
chisq.test() %>%
.[1] %>%
as.numeric(),
N = sum(table_normality_selection),
df = 1)
#### Normality inference
# model fit
ffit_normality_judgment = lm(formula = judgment ~ structure * norm,
data = df.normality)
# anova
aov_normality_judgment = Anova(ffit_normality_judgment,
type = 3)
aov_normality_judgment %>%
as_tibble(rownames = "Term") %>%
print_table()
# partial eta squared
eta_squared(ffit_normality_judgment,
ci = 0.95) %>%
print_table()
##### Power analysis
# post-hoc power analysis
pwr.anova.test(k = 2,
n = df.normality %>%
count(structure) %>%
.$n %>%
min(),
f = aov_normality_judgment$`F value`[1])
### Experiment 2
#### Causal selections
# model fit
ffit_structure_selection = glmer(formula = selection ~ 1 + structure * norm + (1 | participant),
family = "binomial",
data = df.structure)
# analysis of deviance & effect size
aov_structure_selection = Anova(ffit_structure_selection,
type = 3) %>%
as_tibble(rownames = "Term") %>%
mutate(cramers_v = map(`Chisq`, ~ chisq_to_cramers_v(chisq = .,
n = nrow(df.structure),
nrow = 2,
ncol = 2))) %>%
unnest(cramers_v)
aov_structure_selection %>%
print_table()
##### Power analysis
# post-hoc power analysis on the effect of structure on selections
table_structure_selection = table(df.structure$structure,
df.structure$selection)
pwr.chisq.test(w = table_structure_selection %>%
chisq.test() %>%
.[1] %>%
as.numeric(),
N = sum(table_normality_selection),
df = 1)
#### Structure inference
# model fit
# Why simple linear model instead of glm?
ffit_structure_judgment = lm(formula = judgment ~ explanation * norm,
data = df.structure %>%
select(participant,
norm,
explanation,
judgment) %>%
distinct())
# anova
aov_structure_judgment = Anova(ffit_structure_judgment,
type = 3)
aov_structure_judgment %>%
as_tibble(rownames = "Term") %>%
print_table()
# partial eta squared
eta_squared(ffit_structure_judgment,
ci = 0.95) %>%
print_table()
##### Power analysis
# post-hoc power analysis
pwr.anova.test(k = 2,
n = df.structure %>%
select(participant, norm, explanation, judgment) %>%
distinct() %>%
count(explanation) %>%
.$n %>%
min(),
f = aov_structure_judgment$`F value`[1])
# Combined plots
## Selections
p.exp1.selections + p.exp2.selections +
plot_annotation(tag_levels = "A") &
theme(plot.tag = element_text(face = "bold"),
plot.margin = margin(t = 0.1, r = 0.1, l = 0.1, b = 0, unit = "cm"))
ggsave(filename = "../../figures/plots/selections.pdf",
width = 16,
height = 6)
# Session Info
sessionInfo()
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
library("here")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
debugSource("~/GitHub/inference_from_explanation/code/R/all_code.r")
# Load packages
print("kms")
library("knitr")       # for RMarkdown commands
library("kableExtra")  # for nice tables
library("janitor")     # for cleaning column names
library("brms")        # for Bayesian regression modeling
library("tidybayes")   # for Bayesian regression modeling
library("broom.mixed") # for tidy regression results
library("xtable")      # for latex tables
library("ggeffects")   # for marginal effects
library("car")         # for ANOVAs
library("lme4")        # for linear mixed effects models
library("effectsize")  # for calculating effect sizes
library("pwr")         # for power analysis
library("patchwork")   # for figure panels
library("tidyverse")   # for data wrangling, visualization, etc.
library("here")
#here("GitHub/inference_from_explanation")
getwd()
#setwd("C:/Users/psyde/Documents/GitHub/inference_from_explanation")
# set ggplot theme
theme_set(theme_classic())
# suppress summarise() grouping warning
options(dplyr.summarise.inform = F)
# use effects contrast coding to interpret effects from categorical variables as main effects
options(contrasts = c("contr.sum", "contr.poly"))
# Functions
# function for printing out html or latex tables
print_table = function(data, format = "html", digits = 2){
if(format == "html"){
data %>%
kable(digits = digits) %>%
kable_styling()
}else if(format == "latex"){
data %>%
xtable(digits = digits,
caption = "Caption",
label = "tab:table") %>%
print(include.rownames = F,
booktabs = T,
sanitize.colnames.function = identity,
caption.placement = "top")
}
}
# Experiment 1: Normality inference
## Read in data
# CONJUNCTIVE STRUCTURE: STATISTICAL NORMS
df.stat_con_data = read.csv(here("../../data/statistical_conjunctive.csv"),
stringsAsFactors = F) %>%
filter(row_number() > 2) %>% # additional rows in qualtrics csv
clean_names() %>%
filter(!status == "Survey Preview", #exclude preview trials,
!ethnicity == "") #exclude people who did not make it until demographics, i.e. incomplete data
# Reference clip in final test clip: dark motion block is at the top
# in test clip (Recode condition "db")
# Reference slider: picture with dark block at the top is on the right
# of the slider (0-"Normal", 100 "Abnormal") (Recode condition "1 and "4"")
df.stat_con_judgments = df.stat_con_data %>%
mutate(participant = 1:n()) %>%
select(dt_ball_a_1:b_dark_top_right_1, contains("dark_thru"), condition, participant) %>%
pivot_longer(cols = -c(participant, condition),
names_to = "index",
values_to = "value") %>%
filter(value != "") %>%
mutate(index = ifelse(str_detect(index, "conjunctive"),
"conjunctive",
index),
position = str_extract_all(index, "db|dt"),
index = ifelse(str_detect(index, "thru"),
"selection",
index),
index = ifelse(str_detect(index, "top"),
"judgment",
index),
index = str_remove(index, "db_"),
index = str_remove(index, "dt_"),
index = str_remove(index, "_1"),
value = ifelse(value == "Ball E did go through the gate because ball A did go through the motion block.",
"1",
ifelse(value == "Ball E did go through the gate because ball B did go through the motion block.",
2,
value))) %>%
mutate(value = as.numeric(value),
value = ifelse(test = (position == "db" & str_detect(index, "ball")),
yes = 100 - value,
no = value),
value = ifelse((position == "db" & str_detect(index, "selection")),
3 - value,
value)) %>%
select(-position) %>%
pivot_wider(names_from = index,
values_from = value) %>%
mutate(selection = factor(selection,
levels = 1:2,
labels = c("abnormal", "normal"))) %>%
mutate(judgment = ifelse(condition %in% c(1, 4),
100 - judgment,
judgment)) %>%
rename(ball_abnormal = ball_a,
ball_normal = ball_b) %>%
arrange(participant) %>%
# define exclusion criteria
mutate(exclude = ifelse((ball_abnormal < ball_normal) &
(conjunctive < 50), 0, 1))
# CONJUNCTIVE STRUCTURE: PRESCRIPTIVE NORMS
df.pres_con_data = read.csv(here("../../data/prescriptive_conjunctive.csv"),
stringsAsFactors = F) %>%
filter(row_number() > 2) %>% # additional rows in qualtrics csv
clean_names() %>%
filter(!status == "Survey Preview", #exclude preview trials,
!ethnicity == "") #exclude people who did not make until demographics, i.e. incomplete survey
# reference clip:
# Billy is the abnormal agent, Suzy the normal agent (Recode norm_condition "2")
# The selected agent as the abnormal agent is at the top of the
# judgment scale ( Recode learn_condition ="2")
df.pres_con_judgments = df.pres_con_data %>%
mutate(participant = 1:n()) %>%
select(b_abnorm_billy_1:suzy_b_abnorm_right_1,
learn_condition,
condition,
participant,
-starts_with("q"),
-starts_with("timing")) %>%
pivot_longer(cols = -c(participant, learn_condition, condition),
names_to = "index",
values_to = "value") %>%
filter(value != "") %>%
mutate(index = ifelse(str_detect(index, "left|right"),
"judgment",
index))%>%
mutate(index = ifelse(str_detect(index, "b_abnorm_billy_1|s_abnorm_billy_1"),
"agreement_Billy",
index))%>%
mutate(index = ifelse(str_detect(index, "b_abnorm_suzy_1|s_abnorm_suzy_1"),
"agreement_Suzy",
index))%>%
mutate(index = ifelse(str_detect(index, "conjunctive"),
"conjunctive",
index))%>%
mutate(index = ifelse(str_detect(index, "selection"),
"selection",
index))%>%
mutate(value = as.numeric(value),
value = ifelse(test = (learn_condition == "2" & str_detect(index, "agreement")),
yes = 100 - value,
no = value),
value = ifelse((learn_condition == "2" & str_detect(index, "selection")),
3 - value,
value))%>%
pivot_wider(names_from = index,
values_from = value) %>%
mutate(selection = factor(selection,
levels = 1:2,
labels = c("abnormal", "normal"))) %>%
mutate(judgment = ifelse(condition %in% c(1, 4),
100 - judgment,
judgment)) %>%
rename(agreement_abnormal_agent = agreement_Billy,
agreement_normal_agent = agreement_Suzy) %>%
arrange(participant) %>%
# define exclusion criteria
mutate(exclude = ifelse((agreement_abnormal_agent < agreement_normal_agent) &
(conjunctive < 50), 0, 1))
# DISJUNCTIVE STRUCTURE: STATISTICAL NORMS
df.stat_dis_data = read.csv(here("../../data/statistical_disjunctive.csv"),
stringsAsFactors = F) %>%
filter(row_number() > 2) %>% # additional rows in qualtrics csv
clean_names() %>%
filter(!status == "Survey Preview", # exclude preview trials,
!ethnicity == "") # exclude people who did not make until it demographics
# Reference clip in final test clip: dark motion block is at the top in
# test clip (Recode condition "db")
# Reference slider: picture with dark block at the top is on the right of
# the slider (0-"Normal", 100 "Abnormal") (Recode condition "1 and "4"")
df.stat_dis_judgments = df.stat_dis_data %>%
mutate(participant = 1:n()) %>%
select(dt_ball_a_1:b_dark_top_right_1,
contains("dark_thru"),
condition,
participant) %>%
pivot_longer(cols = -c(participant, condition),
names_to = "index",
values_to = "value") %>%
filter(value != "") %>%
mutate(index = ifelse(str_detect(index, "disjunctive"),
"disjunctive",
index),
position = str_extract_all(index, "db|dt"),
index = ifelse(str_detect(index, "thru"),
"selection",
index),
index = ifelse(str_detect(index, "top"),
"judgment",
index),
index = str_remove(index, "db_"),
index = str_remove(index, "dt_"),
index = str_remove(index, "_1"),
value = ifelse(value == "Ball E did go through the gate because ball A did go through the motion block.",
"1",
ifelse(value == "Ball E did go through the gate because ball B did go through the motion block.",
2,
value))) %>%
mutate(value = as.numeric(value),
value = ifelse(test = (position == "db" & str_detect(index, "ball")),
yes = 100 - value,
no = value),
value = ifelse((position == "db" & str_detect(index, "selection")),
3 - value,
value)) %>%
select(-position) %>%
pivot_wider(names_from = index,
values_from = value) %>%
mutate(selection = factor(selection,
levels = 1:2,
labels = c("abnormal", "normal"))) %>%
mutate(judgment = ifelse(condition %in% c(1, 4),
100 - judgment,
judgment)) %>%
rename(ball_abnormal = ball_a,
ball_normal = ball_b) %>%
arrange(participant) %>%
# define exclusion criteria
mutate(exclude = ifelse((ball_abnormal < ball_normal) &
(disjunctive > 50), 0, 1))
# DISJUNCTIVE STRUCTURE: PRESCRIPTIVE NORMS
df.pres_dis_data = read.csv(here("../../data/prescriptive_disjunctive.csv"),
stringsAsFactors = F) %>%
filter(row_number() > 2) %>% # additional rows in qualtrics csv
clean_names() %>%
filter(!status == "Survey Preview", #exclude preview trials,
!age == "") #exclude people who did not make until demographics
# reference clip:
# Billy is the abnormal agent, Suzy the normal agent (Recode norm_condition "2")
# The selected agent as the abnormal agent is at the top of the
# judgment scale (100) ( Recode learn_condition ="2")
df.pres_dis_judgments = df.pres_dis_data %>%
mutate(participant = 1:n()) %>%
select(b_abnorm_billy_1:suzy_b_abnorm_right_1,
learn_condition,
condition,
participant,
-starts_with("q"),
-starts_with("timing")) %>%
pivot_longer(cols = -c(participant, learn_condition, condition),
names_to = "index",
values_to = "value") %>%
filter(value != "") %>%
mutate(index = ifelse(str_detect(index, "left|right"),
"judgment",
index))%>%
mutate(index = ifelse(str_detect(index, "b_abnorm_billy_1|s_abnorm_billy_1"),
"agreement_Billy",
index))%>%
mutate(index = ifelse(str_detect(index, "b_abnorm_suzy_1|s_abnorm_suzy_1"),
"agreement_Suzy",
index))%>%
mutate(index = ifelse(str_detect(index, "disjunctive"),
"disjunctive",
index))%>%
mutate(index = ifelse(str_detect(index, "selection"),
"selection",
index))%>%
mutate(value = as.numeric(value),
value = ifelse(test = (learn_condition == "2" & str_detect(index, "agreement")),
yes = 100 - value,
no = value),
value = ifelse((learn_condition == "2" & str_detect(index, "selection")),
3 - value,
value))%>%
pivot_wider(names_from = index,
values_from = value) %>%
mutate(selection = factor(selection,
levels = 1:2,
labels = c("abnormal", "normal"))) %>%
mutate(judgment = ifelse(condition %in% c(1, 4),
100 - judgment,
judgment)) %>%
rename(agreement_abnormal_agent = agreement_Billy,
agreement_normal_agent = agreement_Suzy) %>%
arrange(participant) %>%
# define exclusion criteria
mutate(exclude = ifelse((agreement_abnormal_agent < agreement_normal_agent) &
(disjunctive > 50), 0, 1))
# COMBINE THE DATA
df.normality = df.stat_con_judgments %>%
mutate(structure = "conjunctive") %>%
rename(structure_question = conjunctive) %>%
bind_rows(df.stat_dis_judgments %>%
mutate(structure = "disjunctive") %>%
rename(structure_question = disjunctive)) %>%
mutate(norm = "statistical") %>%
rename(abnormal_rating = ball_abnormal,
normal_rating = ball_normal,
structure_rating = structure_question) %>%
bind_rows(df.pres_con_judgments %>%
mutate(structure = "conjunctive") %>%
rename(structure_question = conjunctive) %>%
bind_rows(df.pres_dis_judgments %>%
mutate(structure = "disjunctive") %>%
rename(structure_question = disjunctive)) %>%
mutate(norm = "prescriptive") %>%
rename(abnormal_rating = agreement_abnormal_agent,
normal_rating = agreement_normal_agent,
structure_rating = structure_question) %>%
select(- learn_condition)) %>%
filter(exclude == 0) %>% # filter based on exclusion criteria
mutate(participant = 1:n()) %>%
mutate(structure = factor(structure, levels = c("conjunctive", "disjunctive")),
norm = factor(norm, levels = c("statistical", "prescriptive"))) %>%
select(-condition)
source("~/GitHub/inference_from_explanation/code/R/all_code.r")
source("~/GitHub/inference_from_explanation/code/R/all_code.r")
source("~/GitHub/inference_from_explanation/code/R/all_code.r")
source("~/GitHub/inference_from_explanation/code/R/all_code.r")
source("~/GitHub/inference_from_explanation/code/R/all_code.r")
